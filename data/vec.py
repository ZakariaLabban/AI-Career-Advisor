# -*- coding: utf-8 -*-
"""Untitled10.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1D6dAR8sEtKN-CykThfpSgApwCN_Lz2Yh
"""



import openai
from dotenv import load_dotenv
import langchain
# Load environment variables
load_dotenv()
openai.api_key = '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'

# Sample data: A list of skills strings for specific job roles
data = [
    {
        "job_title": "HR Specialist",
        "skills": "Focused on customer satisfaction, Team management, Marketing savvy, Conflict resolution techniques, Training and development, Skilled multi-tasker, Client relations specialist, Organizational skills, Analytical skills, Accounting, Benefits administration, Medical billing, Medical terminology, Financial management, Human Resources, Labor relations, Marketing, Advertising, Data analysis, Performance reviews, Personnel management, Public relations, Budgeting, Website management."
    },
    {
        "job_title": "Data Scientist",
        "skills": "Python, SQL, Machine Learning, Deep Learning, Neural Networks, Data Visualization, Natural Language Processing, Statistical Analysis, Big Data, Hadoop, Spark, Tableau, PowerBI, Predictive Analytics, Data Wrangling, Feature Engineering, Model Deployment."
    }
]

# Function to generate embeddings using OpenAI
def generate_embedding(text):
    try:
        response = openai.Embedding.create(
            model="text-embedding-ada-002",
            input=text
        )
        return response['data'][0]['embedding']
    except Exception as e:
        print(f"Error generating embedding: {e}")
        return None

# Generate embeddings for all skills strings
embeddings = []
for record in data:
    job_title = record['job_title']
    skills = record['skills']
    embedding = generate_embedding(skills)

    if embedding:
        embeddings.append({
            "job_title": job_title,
            "skills": skills,
            "embedding": embedding
        })

# Print the embeddings
for record in embeddings:
    print(f"Job Title: {record['job_title']}")
    print(f"Embedding Length: {len(record['embedding'])}")
    print(f"Embedding: {record['embedding'][:5]}... (truncated)")
    print()



from langchain.vectorstores.pgvector import PGVector
from langchain.docstore.document import Document


from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.vectorstores.pgvector import PGVector
from langchain.docstore.document import Document
import pandas as pd

# Database configuration
CONNECTION_STRING = "postgresql+psycopg2://postgres:test@localhost:5433/vector_db"
COLLECTION_NAME = 'state_of_union_vectors'

# Load the Excel or CSV file
EXCEL_FILE = EXCEL_FILE = r"C:\Users\mahmo\Desktop\ai-adv\new_resumes.csv"
 # Replace with your actual file path
CATEGORY_COLUMN = "Category"  # Replace with the category column name
TEXT_COLUMN = "cleaned_resume"  # Replace with the skills column name

# Read the Excel file
df = pd.read_csv(EXCEL_FILE)

# Ensure the required columns exist
if CATEGORY_COLUMN not in df.columns or TEXT_COLUMN not in df.columns:
    raise ValueError(f"Columns '{CATEGORY_COLUMN}' and/or '{TEXT_COLUMN}' not found in the file.")

# Extract the skills strings (texts) and categories
texts = df[TEXT_COLUMN].astype(str).fillna("").tolist()

# Create metadata from category
metadatas = df[CATEGORY_COLUMN].apply(lambda cat: {"category": cat}).tolist()

# Initialize the embedding model
embedding_model = OpenAIEmbeddings(openai_api_key=openai.api_key)

# Use PGVector to compute embeddings and insert data into the database
db = PGVector.from_texts(
    texts=texts,  # Pass the texts here
    embedding=embedding_model,  # Let PGVector compute embeddings
    collection_name=COLLECTION_NAME,
    connection_string=CONNECTION_STRING,
    metadatas=metadatas
)

print("Data successfully added to PGVector database!")
